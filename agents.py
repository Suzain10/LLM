# -*- coding: utf-8 -*-
"""Agents.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15hIcM-3CeO7iAVg2RJ4y1tYWfiHvqQ43
"""

!pip install -U langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite

import getpass
import os

os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()

import getpass
import os

os.environ["TAVILY_API_KEY"] = getpass.getpass()

from langchain_community.tools.tavily_search import TavilySearchResults

search = TavilySearchResults(max_results=2)
search_results = search.invoke("what is the weather in Srinagar")
print(search_results)
# If we want, we can create other tools.
# Once we have all the tools we want, we can put them in a list that we will reference later.
tools = [search]

! pip install -qU langchain-openai

import getpass
import os

os.environ["OPENAI_API_KEY"] = getpass.getpass()

from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-3.5-turbo-0125")

from langchain_core.messages import HumanMessage

response = model.invoke([HumanMessage(content="Hi")])
response.content

model_with_tools = model.bind_tools(tools)

response = model_with_tools.invoke([HumanMessage(content="Hi!")])

print(f"ContentString: {response.content}")
print(f"ToolCalls: {response.tool_calls}")

response = model_with_tools.invoke([HumanMessage(content="What's the weather in Srinagar?")])

print(f"ContentString: {response.content}")
print(f"ToolCalls: {response.tool_calls}")

from langgraph.prebuilt import create_react_agent

agent_executor = create_react_agent(model, tools)

response = agent_executor.invoke({"messages": [HumanMessage(content="hi!")]})

response["messages"]

response = agent_executor.invoke(
    {"messages": [HumanMessage(content="whats the weather in srinagar?")]}
)
response["messages"]

